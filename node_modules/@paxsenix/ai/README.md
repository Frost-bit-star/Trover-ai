# @paxsenix/ai

A lightweight and intuitive Node.js client for the [Paxsenix AI API](https://api.paxsenix.biz.id/docs).  
Easily integrate AI-powered chat completions, streaming responses, model listing, and moreâ€”right into your app.

**Free to use with a rate limit of 20 requests per minute.**  
Need more? API key support with higher limits is coming soon.

![Static Badge](https://img.shields.io/badge/@PaxSenix-AI-blue)
![GitHub top language](https://img.shields.io/github/languages/top/Paxsenix0/ai)
![GitHub Repo stars](https://img.shields.io/github/stars/Paxsenix0/ai)
![GitHub issues](https://img.shields.io/github/issues/Paxsenix0/ai)
![NPM Downloads](https://img.shields.io/npm/dm/@paxsenix/ai)

---

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
  - [Initialize the Client](#initialize-the-client)
  - [Chat Completions](#chat-completions)
  - [Streaming Chat Completions](#streaming-chat-completions)
  - [List Available Models](#list-available-models)
- [Error Handling](#ï¸-error-handling)
- [Rate Limits](#-rate-limits)
- [Upcoming Features](#-upcoming-features)
- [License](#-license)
- [Feedback & Contributions](#-feedback--contributions)

---

## ğŸš€ Features

- **Chat Completions** â€“ Generate AI-powered responses with ease
- **Streaming Responses** â€“ Get output in real-time as the AI types
- **Model Listing** â€“ Retrieve available model options
- **Planned** â€“ Image generation, embeddings, and more (coming soon)

---

## ğŸ“¦ Installation

```bash
npm install @paxsenix/ai
```

---

## ğŸ“– Usage

### Initialize the Client

```js
import PaxSenixAI from '@paxsenix/ai';

// Without API key (free access)
const paxsenix = new PaxSenixAI();

// With API key (coming soon)
const paxsenix = new PaxSenixAI('YOUR-API-KEY');
```

### Chat Completions

```js
const response = await paxsenix.createChatCompletion({
  model: 'gpt-3.5-turbo',
  messages: [
    { role: 'system', content: 'You are a sarcastic assistant.' },
    { role: 'user', content: 'Wassup beach' }
  ],
  temperature: 0.7,
  max_tokens: 100
});

console.log(response.choices[0].message.content);
```

Or using resource-specific API:

```js
const chatResponse = await paxsenix.Chat.createCompletion({
  model: 'gpt-3.5-turbo',
  messages: [
    { role: 'system', content: 'You are a sarcastic assistant.' },
    { role: 'user', content: 'Who tf r u?' }
  ]
});
```

### Streaming Chat Completions

```js
await paxsenix.Chat.streamCompletion({
  model: 'gpt-3.5-turbo',
  messages: [
    { role: 'system', content: 'You are a sarcastic assistant.' },
    { role: 'user', content: 'Tell me a dark joke.' }
  ]
}, (chunk) => {
  if (chunk.choices?.[0]?.delta?.content) {
    process.stdout.write(chunk.choices[0].delta.content);
  }
});
```

### List Available Models

```js
const models = await paxsenix.listModels();
console.log(models.data);
```

---

## ğŸ› ï¸ Error Handling

```js
try {
  const response = await paxsenix.createChatCompletion({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: 'Hello!' }]
  });
} catch (error) {
  console.error('Status:', error.status);
  console.error('Message:', error.message);
  console.error('Data:', error.data);
}
```

---

## â±ï¸ Rate Limits

- Free access allows up to **20 requests per minute**
- Higher rate limits and API key support are planned
- API keys will offer better stability and priority access (coming soon)

---

## ğŸš§ Upcoming Features

- **Image Generation**
- **Embeddings Support**
- **Token Usage Stats**
- **Billing (for premium access)**

---

## ğŸ“œ License

MIT License. See [LICENSE](LICENSE) for full details.

---

## ğŸ’¬ Feedback & Contributions

Pull requests and issues are welcome.  
Feel free to fork, submit PRs, or just star the repo if it's helpful.